# BachelorProject
This project will explore the oversquashing problem in Graph Neural Networks (GNNs) and how it affects the ability for the model to learn long-range dependencies between nodes.
The project will also explore the use of topological information in the form of the dataset's graph structure to improve the model's ability to learn long-range dependencies.  

Supervised by: Raghavendra Selvan  

## Random thoughts
Attention is analogous to a fully-adjacent graph layer, therefore it is a special case of a GNN.
Therefore, it should be possible to find some trade-off between losing computing efficiency and performance.

Jacobians and stuff show that node to node insensitivity is equivalent to oversquashing and we coudl use this to measure insensitivity in a TDL graph

Learnable topological representaiton.
measuring distances between relevant nodes.

replacing transformer attentoin with tdl based network


